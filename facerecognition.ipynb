{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "facerecognition.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Professor-Sathish/facere/blob/master/facerecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcvVITG77lhm",
        "colab_type": "code",
        "outputId": "125049b6-bcc5-4bce-86b4-33acbc72ea0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = '/content/gdrive/My Drive/ML PROJECTS/face_recognition-master'\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRJTPgXZWj2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gnifLjn8AuU",
        "colab_type": "code",
        "outputId": "6bc3474e-395f-4307-fab9-f3520fab3cf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "pip install face-recognition"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting face-recognition\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face-recognition) (7.0)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.6/dist-packages (from face-recognition) (19.18.0)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n",
            "\u001b[K     |████████████████████████████████| 100.2MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face-recognition) (1.17.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face-recognition) (6.2.2)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566172 sha256=2db338daccae994aed873c7bb6cbb1d67191dba0cc5f99ae51f44a370d06f1c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHCy3dgSQfX7",
        "colab_type": "code",
        "outputId": "b2a84b53-5d0c-49fe-fd98-1b965e62627f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "from PIL import Image\n",
        "import face_recognition\n",
        "\n",
        "# Load the jpg file into a numpy array\n",
        "image = face_recognition.load_image_file(\"/content/gdrive/My Drive/ML PROJECTS/face_recognition-master/tests/test_images/gdg.jpg\")\n",
        "\n",
        "# Find all the faces in the image using a pre-trained convolutional neural network.\n",
        "# This method is more accurate than the default HOG model, but it's slower\n",
        "# unless you have an nvidia GPU and dlib compiled with CUDA extensions. But if you do,\n",
        "# this will use GPU acceleration and perform well.\n",
        "# See also: find_faces_in_picture.py\n",
        "face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=0, model=\"cnn\")\n",
        "\n",
        "print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n",
        "\n",
        "for face_location in face_locations:\n",
        "\n",
        "    # Print the location of each face in this image\n",
        "    top, right, bottom, left = face_location\n",
        "    print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n",
        "     \n",
        "    # You can access the actual face itself like this:\n",
        "    face_image = image[top:bottom, left:right]\n",
        "    pil_image = Image.fromarray(face_image)\n",
        "    pil_image.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I found 39 face(s) in this photograph.\n",
            "A face is located at pixel location Top: 408, Left: 2309, Bottom: 503, Right: 2403\n",
            "A face is located at pixel location Top: 628, Left: 556, Bottom: 707, Right: 635\n",
            "A face is located at pixel location Top: 888, Left: 955, Bottom: 982, Right: 1050\n",
            "A face is located at pixel location Top: 524, Left: 1740, Bottom: 603, Right: 1819\n",
            "A face is located at pixel location Top: 427, Left: 859, Bottom: 522, Right: 954\n",
            "A face is located at pixel location Top: 955, Left: 2011, Bottom: 1050, Right: 2106\n",
            "A face is located at pixel location Top: 460, Left: 1196, Bottom: 539, Right: 1275\n",
            "A face is located at pixel location Top: 572, Left: 1348, Bottom: 651, Right: 1427\n",
            "A face is located at pixel location Top: 1070, Left: 1214, Bottom: 1165, Right: 1309\n",
            "A face is located at pixel location Top: 284, Left: 1268, Bottom: 363, Right: 1347\n",
            "A face is located at pixel location Top: 772, Left: 331, Bottom: 867, Right: 426\n",
            "A face is located at pixel location Top: 1301, Left: 1147, Bottom: 1395, Right: 1242\n",
            "A face is located at pixel location Top: 686, Left: 1646, Bottom: 781, Right: 1741\n",
            "A face is located at pixel location Top: 340, Left: 2124, Bottom: 419, Right: 2203\n",
            "A face is located at pixel location Top: 830, Left: 2251, Bottom: 925, Right: 2346\n",
            "A face is located at pixel location Top: 734, Left: 1099, Bottom: 829, Right: 1194\n",
            "A face is located at pixel location Top: 612, Left: 1172, Bottom: 691, Right: 1251\n",
            "A face is located at pixel location Top: 772, Left: 830, Bottom: 867, Right: 925\n",
            "A face is located at pixel location Top: 404, Left: 1844, Bottom: 483, Right: 1923\n",
            "A face is located at pixel location Top: 612, Left: 1892, Bottom: 691, Right: 1971\n",
            "A face is located at pixel location Top: 801, Left: 2549, Bottom: 896, Right: 2643\n",
            "A face is located at pixel location Top: 356, Left: 1436, Bottom: 435, Right: 1515\n",
            "A face is located at pixel location Top: 648, Left: 955, Bottom: 742, Right: 1050\n",
            "A face is located at pixel location Top: 780, Left: 1460, Bottom: 859, Right: 1539\n",
            "A face is located at pixel location Top: 753, Left: 1905, Bottom: 848, Right: 2000\n",
            "A face is located at pixel location Top: 380, Left: 988, Bottom: 459, Right: 1067\n",
            "A face is located at pixel location Top: 748, Left: 1300, Bottom: 827, Right: 1379\n",
            "A face is located at pixel location Top: 636, Left: 772, Bottom: 715, Right: 851\n",
            "A face is located at pixel location Top: 926, Left: 657, Bottom: 1021, Right: 752\n",
            "A face is located at pixel location Top: 236, Left: 852, Bottom: 315, Right: 931\n",
            "A face is located at pixel location Top: 268, Left: 700, Bottom: 347, Right: 779\n",
            "A face is located at pixel location Top: 196, Left: 2140, Bottom: 275, Right: 2219\n",
            "A face is located at pixel location Top: 475, Left: 1579, Bottom: 570, Right: 1674\n",
            "A face is located at pixel location Top: 620, Left: 1532, Bottom: 699, Right: 1611\n",
            "A face is located at pixel location Top: 324, Left: 1716, Bottom: 403, Right: 1795\n",
            "A face is located at pixel location Top: 972, Left: 155, Bottom: 1086, Right: 269\n",
            "A face is located at pixel location Top: 744, Left: 2097, Bottom: 838, Right: 2192\n",
            "A face is located at pixel location Top: 609, Left: 187, Bottom: 704, Right: 282\n",
            "A face is located at pixel location Top: 532, Left: 2364, Bottom: 611, Right: 2443\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lga0gU6UYSs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing Image class from PIL package  \n",
        "from PIL import Image  \n",
        "# creating a object  \n",
        "im = Image.open(r\"/content/gdrive/My Drive/ML PROJECTS/face_recognition-master/tests/test_images/gdg.jpg\")  \n",
        "im.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5uZ3V1qDez1",
        "colab_type": "code",
        "outputId": "81359e9a-9863-4a8f-c125-9e5951e25b95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "import matplotlib.image as mpimg \n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "testim = mpimg.imread('/content/gdrive/My Drive/ML PROJECTS/face_recognition-master/tests/test_images/gdg.jpg')\n",
        "im1 = testim.crop((left, top, right, bottom))\n",
        "#figure()\n",
        "imshow(im1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-cfaac38fcb7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtestim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/ML PROJECTS/face_recognition-master/tests/test_images/gdg.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mim1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#figure()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'crop'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYYILjaUEM5D",
        "colab_type": "code",
        "outputId": "83604263-1e86-4a33-a24f-c875d3a79d54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
        "\n",
        "img = cv2.imread('/content/gdrive/My Drive/ML PROJECTS/face_recognition-master/tests/test_images/gdg.jpg')\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "for (x,y,w,h) in faces:\n",
        "    img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "    roi_gray = gray[y:y+h, x:x+w]\n",
        "    roi_color = img[y:y+h, x:x+w]\n",
        "    cropped = img[y:y+h, x:x+w]\n",
        "cv2.imwrite(\"thumbnail.png\", cropped)\n",
        "cv2.imshow(\"cropped\", cropped)\n",
        "cv2.waitKey(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-73120b26ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/ML PROJECTS/face_recognition-master/tests/test_images/gdg.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/objdetect/src/cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'detectMultiScale'\n"
          ]
        }
      ]
    }
  ]
}